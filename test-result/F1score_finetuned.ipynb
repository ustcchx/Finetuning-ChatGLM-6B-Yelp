{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8355ad53-0f7d-405d-bac9-a8448be2f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  \n",
    "  \n",
    "def read_jsonl(file_path):  \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:  \n",
    "        for line in file:  \n",
    "            # 去除可能存在的换行符或空格  \n",
    "            line = line.strip() \n",
    "            # 如果该行不为空，则解析为JSON对象  \n",
    "            if line:  \n",
    "                yield json.loads(line)  \n",
    "  \n",
    "# 使用示例  \n",
    "jsonl_file_path = 'finetuned-model\\generated_predictions.jsonl'  \n",
    "temp = []\n",
    "for json_obj in read_jsonl(jsonl_file_path):  \n",
    "    temp.append(json_obj)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f35ab088-fe8c-4858-9859-a04027da8a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_num(string):\n",
    "    for i in range(len(string)):\n",
    "        if string[i].isdigit():\n",
    "            return string[i]\n",
    "    return '-1'\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for obj in temp:\n",
    "    if obj['label'] == \"\":\n",
    "        continue # 超出长度被截断\n",
    "    y_pred.append(int(first_num(obj['predict'])))\n",
    "    y_true.append(int(first_num(obj['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebaa8b7c-df8a-433d-b32b-fe56b0c3b241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (micro): 0.6952687569988801\n",
      "F1 Score (macro): 0.5793098237539764\n",
      "F1 Score (weighted): 0.6951754336657769\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_micro = f1_score(y_true, y_pred, average='micro')  \n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')  \n",
    "f1_weighted = f1_score(y_true, y_pred, average='weighted')  \n",
    "  \n",
    "print('F1 Score (micro):', f1_micro)  \n",
    "print('F1 Score (macro):', f1_macro)  \n",
    "print('F1 Score (weighted):', f1_weighted)\n",
    "\n",
    "# 'micro' 计算全局的F1分数  \n",
    "# 'macro' 计算每个类别的F1分数，然后取平均值，不考虑标签不平衡  \n",
    "# 'weighted' 计算每个类别的F1分数，然后取平均值，但是会考虑标签不平衡（即每个类别的样本数）  \n",
    "# 'samples' 计算每个样本的F1分数，然后取平均值（在多标签分类任务中使用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c4c5bf-df4a-44c7-a234-a73dd62c503a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6952687569988801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_true, y_pred)  \n",
    "print('Accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_for_deeplearning",
   "language": "python",
   "name": "test_for_deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
